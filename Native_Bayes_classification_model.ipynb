{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocn76jW-cLNs",
        "outputId": "763ffe30-0459-4aef-c6e6-c0ecc219bea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                                   text label Unnamed: 2  \\\n",
            "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE        NaN   \n",
            "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE        NaN   \n",
            "2     U.S. Secretary of State John F. Kerry said Mon...  REAL        NaN   \n",
            "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE        NaN   \n",
            "4     It's primary day in New York and front-runners...  REAL        NaN   \n",
            "...                                                 ...   ...        ...   \n",
            "7790  The State Department told the Republican Natio...  REAL        NaN   \n",
            "7791  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE        NaN   \n",
            "7792   Anti-Trump Protesters Are Tools of the Oligar...  FAKE        NaN   \n",
            "7793  ADDIS ABABA, Ethiopia —President Obama convene...  REAL        NaN   \n",
            "7794  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL        NaN   \n",
            "\n",
            "     Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8  \\\n",
            "0           NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "1           NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "2           NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "3           NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "4           NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "...         ...        ...        ...        ...        ...        ...   \n",
            "7790        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "7791        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "7792        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "7793        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "7794        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "\n",
            "     Unnamed: 9  ... Unnamed: 129 Unnamed: 130 Unnamed: 131 Unnamed: 132  \\\n",
            "0           NaN  ...          NaN          NaN          NaN          NaN   \n",
            "1           NaN  ...          NaN          NaN          NaN          NaN   \n",
            "2           NaN  ...          NaN          NaN          NaN          NaN   \n",
            "3           NaN  ...          NaN          NaN          NaN          NaN   \n",
            "4           NaN  ...          NaN          NaN          NaN          NaN   \n",
            "...         ...  ...          ...          ...          ...          ...   \n",
            "7790        NaN  ...          NaN          NaN          NaN          NaN   \n",
            "7791        NaN  ...          NaN          NaN          NaN          NaN   \n",
            "7792        NaN  ...          NaN          NaN          NaN          NaN   \n",
            "7793        NaN  ...          NaN          NaN          NaN          NaN   \n",
            "7794        NaN  ...          NaN          NaN          NaN          NaN   \n",
            "\n",
            "     Unnamed: 133 Unnamed: 134 Unnamed: 135 Unnamed: 136 Unnamed: 137  \\\n",
            "0             NaN          NaN          NaN          NaN          NaN   \n",
            "1             NaN          NaN          NaN          NaN          NaN   \n",
            "2             NaN          NaN          NaN          NaN          NaN   \n",
            "3             NaN          NaN          NaN          NaN          NaN   \n",
            "4             NaN          NaN          NaN          NaN          NaN   \n",
            "...           ...          ...          ...          ...          ...   \n",
            "7790          NaN          NaN          NaN          NaN          NaN   \n",
            "7791          NaN          NaN          NaN          NaN          NaN   \n",
            "7792          NaN          NaN          NaN          NaN          NaN   \n",
            "7793          NaN          NaN          NaN          NaN          NaN   \n",
            "7794          NaN          NaN          NaN          NaN          NaN   \n",
            "\n",
            "     Unnamed: 138  \n",
            "0             NaN  \n",
            "1             NaN  \n",
            "2             NaN  \n",
            "3             NaN  \n",
            "4             NaN  \n",
            "...           ...  \n",
            "7790          NaN  \n",
            "7791          NaN  \n",
            "7792          NaN  \n",
            "7793          NaN  \n",
            "7794          NaN  \n",
            "\n",
            "[7795 rows x 139 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3283853804.py:5: DtypeWarning: Columns (22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/TrueFalse/fake_or_real_news.csv')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/TrueFalse/fake_or_real_news.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Data Cleaning and Selecting Columns\n",
        "\n",
        "# Usually, one column has the text and another has 'FAKE' or 'REAL' labels.\n",
        "# Let's find which columns have those values.\n",
        "print(df.nunique())   # Check unique value counts per column\n",
        "\n",
        "# Identify columns manually if needed:\n",
        "# Suppose column 0 = text, column 1 = label\n",
        "# (Adjust these column names based on your dataset)\n",
        "df = df.iloc[:, [0, 1]]\n",
        "df.columns = ['text', 'label']\n",
        "\n",
        "# Drop rows with missing values\n",
        "df = df.dropna(subset=['text', 'label'])\n",
        "\n",
        "# Normalize label values (remove spaces, make uppercase)\n",
        "df['label'] = df['label'].astype(str).str.strip().str.upper()\n",
        "\n",
        "# Keep only FAKE and REAL labels\n",
        "df = df[df['label'].isin(['FAKE', 'REAL'])]\n",
        "\n",
        "print(\"\\nCleaned dataset shape:\", df.shape)\n",
        "print(df['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvOjJvGpgdj3",
        "outputId": "5615966a-d974-4002-b66d-96b657eb4b87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text            6644\n",
            "label            437\n",
            "Unnamed: 2       315\n",
            "Unnamed: 3       241\n",
            "Unnamed: 4       179\n",
            "                ... \n",
            "Unnamed: 134       1\n",
            "Unnamed: 135       1\n",
            "Unnamed: 136       1\n",
            "Unnamed: 137       1\n",
            "Unnamed: 138       1\n",
            "Length: 139, dtype: int64\n",
            "\n",
            "Cleaned dataset shape: (6315, 2)\n",
            "label\n",
            "REAL    3161\n",
            "FAKE    3154\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3: Split Data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Testing samples:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEaJtKFzgjor",
        "outputId": "3d9f864f-3683-4ad5-e5a5-989bb510e8ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 5052\n",
            "Testing samples: 1263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4: Convert Text to Numerical Features (TF-IDF)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_df=0.95, min_df=2)\n",
        "\n",
        "# Fit on training data and transform both train & test\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF shape (train):\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF shape (test):\", X_test_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3qWx16qgpOt",
        "outputId": "123c0a80-c4a5-4211-bec7-f694b7d53bc0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF shape (train): (5052, 35140)\n",
            "TF-IDF shape (test): (1263, 35140)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 5: Train Naive Bayes Model\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Initialize and train model\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\" Model training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gp_vE7Rgyic",
        "outputId": "2bd9d117-03c4-44d8-f6cf-9374a4024ed1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 6: Evaluate Model Performance\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Make predictions\n",
        "y_pred = nb.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp7QQEWgg57c",
        "outputId": "6fa4d339-b227-4221-f86c-6f58b3e007ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8796516231195566\n",
            "\n",
            "Confusion Matrix:\n",
            " [[506 125]\n",
            " [ 27 605]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.95      0.80      0.87       631\n",
            "        REAL       0.83      0.96      0.89       632\n",
            "\n",
            "    accuracy                           0.88      1263\n",
            "   macro avg       0.89      0.88      0.88      1263\n",
            "weighted avg       0.89      0.88      0.88      1263\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 8: Interpret Results and Summarize Findings\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1️⃣ Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the model: {accuracy:.4f}\")\n",
        "\n",
        "# 2️⃣ Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_df = pd.DataFrame(cm, index=nb.classes_, columns=nb.classes_)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm_df)\n",
        "\n",
        "# 3️⃣ Classification Report\n",
        "report = classification_report(y_test, y_pred, target_names=nb.classes_)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "# 4️⃣ Top Features for each class\n",
        "feature_names = np.array(tfidf.get_feature_names_out())\n",
        "class_labels = nb.classes_\n",
        "topn = 10\n",
        "\n",
        "for i, label in enumerate(class_labels):\n",
        "    top_features = feature_names[np.argsort(nb.feature_log_prob_[i])[-topn:]]\n",
        "    print(f\"\\nTop {topn} indicative words for class '{label}':\")\n",
        "    print(top_features)\n",
        "\n",
        "# 5️⃣ Summary text\n",
        "summary = f\"\"\"\n",
        "Summary of Findings:\n",
        "\n",
        "1. Model Accuracy: {accuracy:.2%} — high accuracy indicates the model correctly predicts most news articles.\n",
        "2. Confusion Matrix:\n",
        "{cm_df.to_string()}\n",
        "   - True Positives and True Negatives show correct predictions.\n",
        "   - False Positives and False Negatives indicate misclassifications.\n",
        "3. Classification Report:\n",
        "{report}\n",
        "4. Top words for FAKE news: {', '.join(feature_names[np.argsort(nb.feature_log_prob_[0])[-topn:]])}\n",
        "5. Top words for REAL news: {', '.join(feature_names[np.argsort(nb.feature_log_prob_[1])[-topn:]])}\n",
        "\n",
        "Conclusion:\n",
        "The Naive Bayes classifier effectively distinguishes between FAKE and REAL news articles.\n",
        "TF-IDF vectorization captures important keywords, showing clear differences in language patterns.\n",
        "Naive Bayes is a simple, fast, and interpretable model suitable for text classification tasks like fake news detection.\n",
        "\"\"\"\n",
        "\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLnpeGQjhY47",
        "outputId": "3733c659-666c-43a5-a215-c794d2251b38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 0.8797\n",
            "\n",
            "Confusion Matrix:\n",
            "      FAKE  REAL\n",
            "FAKE   506   125\n",
            "REAL    27   605\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.95      0.80      0.87       631\n",
            "        REAL       0.83      0.96      0.89       632\n",
            "\n",
            "    accuracy                           0.88      1263\n",
            "   macro avg       0.89      0.88      0.88      1263\n",
            "weighted avg       0.89      0.88      0.88      1263\n",
            "\n",
            "\n",
            "Top 10 indicative words for class 'FAKE':\n",
            "['just' 'said' 'russia' 'fbi' 'election' 'people' '2016' 'hillary'\n",
            " 'clinton' 'trump']\n",
            "\n",
            "Top 10 indicative words for class 'REAL':\n",
            "['state' 'cruz' 'republican' 'president' 'campaign' 'sanders' 'obama'\n",
            " 'clinton' 'said' 'trump']\n",
            "\n",
            "Summary of Findings:\n",
            "\n",
            "1. Model Accuracy: 87.97% — high accuracy indicates the model correctly predicts most news articles.\n",
            "2. Confusion Matrix:\n",
            "      FAKE  REAL\n",
            "FAKE   506   125\n",
            "REAL    27   605\n",
            "   - True Positives and True Negatives show correct predictions.\n",
            "   - False Positives and False Negatives indicate misclassifications.\n",
            "3. Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        FAKE       0.95      0.80      0.87       631\n",
            "        REAL       0.83      0.96      0.89       632\n",
            "\n",
            "    accuracy                           0.88      1263\n",
            "   macro avg       0.89      0.88      0.88      1263\n",
            "weighted avg       0.89      0.88      0.88      1263\n",
            "\n",
            "4. Top words for FAKE news: just, said, russia, fbi, election, people, 2016, hillary, clinton, trump\n",
            "5. Top words for REAL news: state, cruz, republican, president, campaign, sanders, obama, clinton, said, trump\n",
            "\n",
            "Conclusion:\n",
            "The Naive Bayes classifier effectively distinguishes between FAKE and REAL news articles.\n",
            "TF-IDF vectorization captures important keywords, showing clear differences in language patterns.\n",
            "Naive Bayes is a simple, fast, and interpretable model suitable for text classification tasks like fake news detection.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}